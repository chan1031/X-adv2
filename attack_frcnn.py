"""
Xray Adversarial Attack
"""
import os
import sys
import cv2
import math
import time
import torch
import random
import argparse
import warnings
import numpy as np
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.distributions import Categorical
from model import FasterRCNNVGG16, FasterRCNNTrainer

from data.dataset import RCNNDetectionDataset, rcnn_detection_collate_attack, RCNNAnnotationTransform
from data import config
from utils import stick, renderer, rl_utils

warnings.filterwarnings("ignore")
torch.set_default_tensor_type('torch.FloatTensor')


parser = argparse.ArgumentParser(description="X-ray adversarial attack.")
# for model
parser.add_argument('--seed', default=0, type=int,
                    help='Random seed for the experiments')
parser.add_argument("--ckpt_path", default="./ckpt/OPIX.pth", type=str, 
                    help="the checkpoint path of the model")
# for data
parser.add_argument('--dataset', default="OPIXray", type=str, 
                    choices=["OPIXray", "HiXray"], help='Dataset name')
parser.add_argument("--phase", default="test", type=str, 
                    help="the phase of the X-ray image dataset")
parser.add_argument("--batch_size", default=10, type=int, 
                    help="the batch size of the data loader")
parser.add_argument("--num_workers", default=4, type=int, 
                    help="the number of workers of the data loader")
# for patch
parser.add_argument("--obj_path", default="objs/simple_door_key2.obj", type=str, #ì´ˆê¸° 3D ì ëŒ€ì  ê°ì²´ obj íŒŒì¼ì˜ ìœ„ì¹˜ ì§€ì •
                    help="the path of adversarial 3d object file")
parser.add_argument("--patch_size", default=35, type=int, #íŒ¨ì¹˜ì˜ ì‚¬ì´ì¦ˆ
                    help="the size of X-ray patch")
parser.add_argument("--patch_count", default=1, type=int, #ì ëŒ€ì  íŒ¨ì¹˜ì˜ ìˆ«ì
                    help="the number of X-ray patch")
parser.add_argument("--patch_place", default="reinforce", type=str, choices=['none', 'fix', 'fix_patch', 'reinforce'],
                    help="the place where the X-ray patch located") #ì ëŒ€ì  ê°ì²´ì˜ ìœ„ì¹˜ ì§€ì •
parser.add_argument("--patch_material", default="iron", type=str, choices=["iron", "plastic", "aluminum", "iron_fix"],
                    help="the material of patch, which decides the color of patch")  #ì ëŒ€ì  ê°ì²´ì˜ ì¬ì§ˆ ì§€ì •   
# for attack
parser.add_argument("--targeted", default=False, action="store_true",
                    help="whether to use targeted (background) attack") #íƒ€ê²Ÿ ì–´íƒ ì—¬ë¶€ ì§€ì •
parser.add_argument("--lr", default=0.01, type=float,  #í•™ìŠµë¥ 
                    help="the learning rate of attack")
parser.add_argument("--beta", default=0.01, type=float, 
                    help="the perceptual loss rate of attack") #ì§€ê°ì  ì†ì‹¤ (ì¦‰, ì™œê³¡ì— ëŒ€í•œ ë¶€ë¶„)
parser.add_argument("--num_iters", default=24, type=int, #ë°˜ë³µìˆ˜ ì„¤ì •
                    help="the number of iterations of attack")
parser.add_argument("--save_path", default="./results", type=str,
                    help="the save path of adversarial examples")

timer = time.time()
def stime(content):
    global timer
    torch.cuda.synchronize()
    print(content, time.time() - timer)
    timer = time.time()

def fix_seed(seed=0):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True

args = parser.parse_args()
args.save_path = os.path.join(args.save_path, f"{args.dataset}/{args.patch_material}/{args.patch_place}", "FasterRCNN")

fix_seed(args.seed)
print(args)

#---------------------------- new function ----------------------------------
#ì „ì²´ ì§€ê°ì†ì‹¤í•¨ìˆ˜ ë¶€ë¶„
def shape_loss(
    vertices_ori, 
    vertices_adv,
    z_weight=1.0,
    mask=None
):
    """
    ì›ë³¸ ì—´ì‡  ë©”ì‰¬(vertices_ori)ì™€ ì—…ë°ì´íŠ¸ëœ ë©”ì‰¬(vertices_adv) ê°„ L2 ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ë˜,
    zì¶• ë³€í™”ì—ëŠ” z_weight ê°€ì¤‘ì¹˜ë¥¼ ê³±í•´ ë‘ê»˜ ë³€í™”ë¥¼ ì–µì œí•˜ëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜.
    """
    # (1) ì¢Œí‘œ ì°¨ì´ ê³„ì‚°
    diff = vertices_adv - vertices_ori
    dx = diff[:, 0]
    dy = diff[:, 1]
    dz = diff[:, 2]

    # (2) zì¶•ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
    dist_all = torch.sqrt(dx**2 + dz**2 + (z_weight * dy)**2 + 1e-8)

    # (3) ë§ˆìŠ¤í¬ê°€ ìˆë‹¤ë©´, ê·¸ ë¶€ë¶„ë§Œ í‰ê· 
    #     ì˜ˆ: groove_mask, blade_mask ë“±
    if mask is not None:
        dist_all = dist_all[mask]
        if dist_all.numel() == 0:
            return torch.tensor(0.0, device=vertices_adv.device)
    
    # (4) ì „ì²´ í‰ê· 
    return dist_all.mean()

def load_groove_coords(txt_path, mean=0.5, std=1/2.4):
    """
    txt íŒŒì¼ì—ì„œ 'v x y z' í˜•íƒœì˜ ì¢Œí‘œë¥¼ ë¶ˆëŸ¬ì˜¤ê³ ,
    ì •ê·œí™”ë¥¼ ì ìš©í•˜ì—¬ (M, 3) shapeì˜ í…ì„œë¡œ ë°˜í™˜.
    """
    coords = []
    with open(txt_path, "r") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            tokens = line.split()
            if tokens[0] == 'v':
                x, y, z = float(tokens[1]), float(tokens[2]), float(tokens[3])
                coords.append([x, y, z])
    groove_coords = torch.tensor(coords, dtype=torch.float32)
    
    #ì¶• ë³€ê²½
    temp_y = groove_coords[:, 1].clone()
    groove_coords[:, 1] = groove_coords[:, 2]  # Y <- Z
    groove_coords[:, 2] = -temp_y   
    # ì •ê·œí™” ì ìš©: OBJì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•˜ê²Œ
    groove_coords = (groove_coords * std) + mean
    
    return groove_coords


def create_groove_mask(vertices, groove_coords):
    """
    vertices: (N, 3) - OBJì—ì„œ ë¶ˆëŸ¬ì˜¨ ì „ì²´ ì •ì  (GPUì— ìˆìŒ)
    groove_coords: (M, 3) - txt íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¨, ì •ê·œí™”ëœ í™ˆ ì •ì  ì¢Œí‘œ (CPU ë˜ëŠ” GPU)
    
    ë°˜í™˜: groove_mask: (N,) bool í…ì„œ
          ê° ì •ì ì´ í™ˆ ì˜ì—­ì´ë©´ True.
          ì˜¤ì§ ì™„ì „íˆ ë™ì¼í•œ ì¢Œí‘œì¸ ê²½ìš°ì—ë§Œ Trueë¡œ ì²˜ë¦¬.
    """
    N = vertices.shape[0]
    groove_mask = torch.zeros(N, dtype=torch.bool, device=vertices.device)
    
    # groove_coordsë¥¼ verticesì™€ ë™ì¼í•œ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
    groove_coords = groove_coords.to(vertices.device)
    
    # ê° groove ì¢Œí‘œì™€ ì •í™•íˆ ë™ì¼í•œ ì •ì ì„ ì°¾ì•„ Trueë¡œ ì„¤ì •
    for gc in groove_coords:
        # ê° ì •ì ê³¼ gcê°€ ì™„ì „íˆ ê°™ì€ì§€ ë¹„êµ (ëª¨ë“  ì¢Œí‘œê°’ì´ ë™ì¼í•´ì•¼ í•¨)
        equal_mask = (vertices == gc).all(dim=1)  # (N,) bool í…ì„œ
        groove_mask |= equal_mask  # OR ì—°ì‚°ì„ í†µí•´ í•´ë‹¹ ì •ì ì„ ë§ˆìŠ¤í‚¹
        
    # ë””ë²„ê¹…: Trueì¸ ì •ì  ê°œìˆ˜ ì¶œë ¥
    true_count = groove_mask.sum().item()
    print(f"ğŸ› ï¸ Groove Mask Debug: {true_count}ê°œì˜ ì •ì ì´ í™ˆ ì˜ì—­ìœ¼ë¡œ ì„¤ì •ë¨.")
    return groove_mask

#---------------------------------------------------------------------------

#ê³ ì •ëœ ìœ„ì¹˜ì— ì ëŒ€ì  ê°ì²´ ìœ„ì¹˜
def get_place_fix(images, bboxes):
    fix_place_list = ["nw", "ne", "sw", "se", "n", "s", "w", "e"]
    areas_choose = [[] for _ in range(len(images))] #ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ len(images)ê°€ 3ì´ë©´ [[],[],[]] ì´ë ‡ê²Œ 3ê°œê°€ ìƒê¹€
    for i in range(args.patch_count):
        places = stick.cal_stick_place_rcnn(bboxes, args.patch_size, args.patch_size, 0.25, fix_place_list[i]) #ê° íŒ¨ì¹˜ë³„ë¡œ nw,ne,sw...ë“±ì˜ ìœ„ì¹˜ì— bbox ì¢Œí‘œê·¼ì²˜ì— ì ì ˆí•œ ìœ„ì¹˜ë¥¼ í• ë‹¹í•¨
        for j in range(len(places)):
            areas_choose[j].append(places[j])
            
    return areas_choose

#ê°•í™”í•™ìŠµìœ¼ë¡œ ê°ì²´ì˜ ìœ„ì¹˜ ì§€ì •
def get_place_reinforce(images, bboxes, group, faces, trainer):
    actor = rl_utils.Actor(args.patch_count).cuda()
    actor.train()
    actor_optim = optim.Adam(actor.parameters(), lr=9e-4)

    areas = stick.get_stick_area_rcnn(bboxes, args.patch_size, args.patch_size)
    area_lens = torch.FloatTensor([len(elm) for elm in areas]).unsqueeze(1)

    pad = nn.ZeroPad2d(args.patch_size)
    group_clamp = torch.clamp(group, 0, 1)

    # use X-ray renderer to convert a 3D object to an X-ray image
    rend_group = []
    for pt in range(args.patch_count):
        depth_img = renderer.ball2depth(group_clamp[pt], faces, args.patch_size, args.patch_size).unsqueeze(0).unsqueeze(0)
        # simulate function needs a 4-dimension input
        rend, mask = renderer.simulate(depth_img, args.patch_material)
        rend[~mask] = 1
        rend_group.append(rend)

    # Using running mean/std to stablize the reward
    reward_ms = rl_utils.RunningMeanStd(shape=(1,), device="cuda:0")

    last_reward = 0
    ori_shape = [e.shape for e in images]

    for rep in range(200):
        print("RL phase", rep + 1)
        # sample actions
        action_logits = []
        for s in range(len(images)):
            # resize(images[s], (224, 224))
            action_logits.append(actor(images[s].unsqueeze(0)))
        action_logits = torch.cat(action_logits, dim=0)
        dist = Categorical(logits=action_logits)
        actions = dist.sample()

        places = (area_lens * actions.detach().cpu() / 50).floor().long()
        areas_choose = []
        for bi in range(places.shape[0]):
            area_choose = []
            for pi in range(places.shape[1]):
                area_choose.append(areas[bi][places[bi, pi]])
            areas_choose.append(area_choose)

        # get rewards
        images_delta = [e.clone().detach() for e in images]
        images_delta = [pad(e) for e in images_delta]
        for pt in range(args.patch_count):
            rend = rend_group[pt]
            for s in range(len(images_delta)):
                u, v = areas_choose[s][pt]
                images_delta[s][:, u+args.patch_size:u+2*args.patch_size, v+args.patch_size:v+2*args.patch_size].mul_(rend[0])

        images_cutpad = []
        for s in range(len(images_delta)):
            images_cutpad.append(images_delta[s][:, args.patch_size:ori_shape[s][1]+args.patch_size, args.patch_size:ori_shape[s][2]+args.patch_size])

        rewards = []
        with torch.no_grad():
            for s in range(len(images_cutpad)):
                trainer.reset_meters()
                loss_cls = trainer.forward(images_cutpad[s].unsqueeze(0), bboxes[s].unsqueeze(0), labels[s].unsqueeze(0), scales[s])
                rewards.append(loss_cls.rpn_cls_loss + loss_cls.roi_cls_loss)
        rewards = torch.stack(rewards, dim=0).unsqueeze(1).detach()

        if actions.shape[-1] > 1:
            reward_penal = actions.float().std(dim=-1, keepdim=True)
        else:
            reward_penal = torch.tensor([0.]).cuda()
        print(rewards.mean().item(), reward_penal.mean().item())
        rewards += 0.01 * reward_penal

        # early stopping
        cur_reward = rewards.mean().item()
        if cur_reward == last_reward:
            break
        last_reward = cur_reward
            
        # standarize rewards
        reward_ms.update(rewards)
        rewards = (rewards - reward_ms.mean) / torch.sqrt(reward_ms.var)

        # learn
        log_prob = dist.log_prob(actions)
        loss = -(rewards * log_prob).mean()

        actor_optim.zero_grad()
        loss.backward()
        actor_optim.step()

        actions = actions.float()

    return areas_choose


def attack(images, bboxes, labels, net, trainer): #(ì´ë¯¸ì§€ë“¤,bboxì •ë³´, ì •ë‹µ í´ë˜ìŠ¤ ë¼ë²¨,ëª¨ë¸,í•™ìŠµì„ ì‹œí‚¤ëŠ” trainer ê°ì²´)
    """
    Main attack function.
    """
    net.phase = "train" #íƒì§€ ëª¨ë¸ì„ í›ˆë ¨ëª¨ë“œë¡œ ë³€í™˜
    images = [e.cuda() for e in images] 
    bboxes = [b.cuda() for b in bboxes]
    labels = [l.cuda() for l in labels] #Gpuë¡œ ì´ë™

    #í™ˆ ë¶€ë¶„ì˜ ì •ì ë“¤ ë¡œë“œ
    groove_coords = load_groove_coords("groove_points.txt")  # (M, 3)
    
    # create a group of patch objects which have same faces
    # we only optimize the coordinate of vertices
    # but not to change the adjacent relation
    group = []
    for _ in range(args.patch_count):
        vertices, faces = renderer.load_from_file(args.obj_path) #3D objectì˜ ì ê³¼ ë©´ì„ ë¶ˆëŸ¬ì˜´
        groove_mask = create_groove_mask(vertices, groove_coords)
        group.append(vertices.unsqueeze(0))
    
    adj_ls = renderer.adj_list(vertices, faces) #verticesë¥¼ ì—°ê²°í•˜ëŠ” line
    
    # the shape of group: [patch_count, 3, vertices_count]
    group = torch.cat(group, dim=0).cuda() #groupëŠ” 3D ì ëŒ€ì  ê°ì²´ë“¤ì˜ verticesê°€ ë“¤ì–´ìˆìŒ
    group_ori = group.clone().detach() #ì›ë³¸ 3Dê°ì²´ë¥¼ ì €ì¥
    depth_patch = torch.zeros((1, args.patch_count, args.patch_size, args.patch_size)).uniform_().cuda()

    #ìµœì ì˜ ìœ„ì¹˜ ê³„ì‚° (fixì¸ì§€ ê°•í™”í•™ìŠµì¸ì§€ ê²°ì •)
    if not args.patch_place == "fix_patch": #ê°•í™”í•™ìŠµìœ¼ë¡œ ì„¤ì •í•œ ê²½ìš°
        group.requires_grad_(True) #groupì„ í•™ìŠµ ëŒ€ìƒìœ¼ë¡œ ì§€ì •
        optimizer = optim.Adam([group], lr=args.lr) #groupì„ ìµœì í™” ëŒ€ìƒìœ¼ë¡œ ì§€ì •
    else:
        depth_patch.requires_grad_(True)
        optimizer = optim.Adam([depth_patch], lr=args.lr)
    # we need a pad function to prevent that a part of patch is out of the image
    pad = nn.ZeroPad2d(args.patch_size)
    
    print("Calculate best place before attack...")

    if args.patch_place == "fix" or args.patch_place == "fix_patch":
        areas_choose = get_place_fix(images, bboxes)
    elif args.patch_place == "reinforce":
        areas_choose = get_place_reinforce(images, bboxes, group, faces, trainer)

    print("Attacking...")
    ori_shape = [e.shape for e in images] #ì›ë³¸ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥´ ë˜ëŒë¦¬ê¸° ìœ„í•¨
    for t in range(args.num_iters):
        timer = time.time()
        #ê³µê²©ì„ í•˜ê¸° ì „ ì›ë³¸ ì´ë¯¸ì§€ì˜ ë³µì‚¬ë³¸ì¸ images_deltaë¥¼ ë§Œë“¤ê³  deltaì— ê³µê²©ì„ ê°€í•¨
        images_delta = [e.clone().detach() for e in images]
        images_delta = [pad(e) for e in images_delta] #íŒ¨ë”© ì¶”ê°€
        
        # calculate the perspective loss
        #ì§€ê° ì†ì‹¤ì„ ê³„ì‚°í•˜ì—¬ íŒ¨ì¹˜ê°€ ë„ˆë¬´ ë³€í˜•ë˜ì§€ ì•Šê²Œ í•¨
        loss_per = torch.zeros((1,)).cuda() #ì§€ê°ì†ì‹¤í•¨ìˆ˜
        if not args.patch_place == "fix_patch": #fix_patchì´ë©´ ê³ ì •ëœí˜•íƒœë¥¼ ìœ ì§€í•˜ë¯€ë¡œ ì§€ê°ì†ì‹¤(tv)ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìŒ
            # TV + Shape ìœ ì‚¬ì„± ì†ì‹¤ì„ í•©ì³ì„œ ê³„ì‚°
            tv_sum = 0.0
            shape_sum = 0.0
            
            for pt in range(args.patch_count): #tv loss ê³„ì‚°
                # (1) ê¸°ì¡´ TV ì†ì‹¤ (ìŠ¤íŒŒì´í¬ ì–µì œ)
                tv_val = renderer.tvloss(group_ori[pt], group[pt], adj_ls, coe=0)
                tv_sum += tv_val
                
                # (2) Shape ìœ ì‚¬ì„± ì†ì‹¤ (ì›ë³¸ ì—´ì‡  í˜•íƒœ ìœ ì§€)
                shape_val = shape_loss(
                    group_ori[pt], 
                    group[pt],
                    z_weight=2.0,
                    mask = groove_mask
                    )
                
                shape_sum += shape_val
                
            # patch_countë¡œ í‰ê· 
            tv_sum /= args.patch_count
            shape_sum /= args.patch_count
            
            # ì›í•˜ëŠ” ë¹„ìœ¨(Î³)ë¡œ ë‘ ì†ì‹¤ì„ í•©ì‚°
            gamma = 0.7  
            loss_per = tv_sum + gamma * shape_sum
        
        # clamp the group into [0, 1]
        #ê°’ì„ 0~1ì‚¬ì´ë¡œ ì •ê·œí™”
        group_clamp = torch.clamp(group, 0, 1)
        depth_clamp = torch.clamp(depth_patch, 0, 1)
        
        # use X-ray renderer to convert a 3D object to an X-ray image
        '''
        íŒ¨ì¹˜ë¥¼ x-rayí™” í•˜ëŠ” ë²•
        1)ìš°ì„  3D íŒ¨ì¹˜ì˜ depthì´ë¯¸ì§€ë¥¼ êµ¬í•¨ (2D ì´ë¯¸ì§€ì¸ë° zì˜ ê°’ì— ë”°ë¼ ì¦‰, ê¹Šì´ì— ë”°ë¼ ê° í”½ì…€ì˜ ê°•ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì´ë¯¸ì§€)
        2)depth iamgeë¥¼ x-rayì— íˆ¬ì˜
        3)x-rayí™” ëœ íŒ¨ì¹˜ë¥¼ ì´ë¯¸ì§€ì— ì‚½ì…
        '''
        for pt in range(args.patch_count):
            if not args.patch_place == "fix_patch": 
                #depth ì´ë¯¸ì§€ êµ¬í•˜ê¸°
                depth_img = renderer.ball2depth(group_clamp[pt], faces, args.patch_size, args.patch_size).unsqueeze(0).unsqueeze(0)
            else:
                depth_img = depth_clamp[:, pt:pt+1]
            # simulate function needs a 4-dimension input
            #depth imageë¥¼ x-rayí™”
            rend, mask = renderer.simulate(depth_img, args.patch_material.replace("_fix", ""))
            rend[~mask] = 1
            #x-ray ì´ë¯¸ì§€ì— íŒ¨ì¹˜ë¥¼ ì ìš©
            for s in range(len(images_delta)):
                u, v = areas_choose[s][pt] #íŒ¨ì¹˜ë¥¼ ì ìš©í•  ìœ„ì¹˜ u,v
                # print(rend.shape, images_delta[s].shape)
                # print(u, v, bboxes[s])
                images_delta[s][:, u+args.patch_size:u+2*args.patch_size, v+args.patch_size:v+2*args.patch_size].mul_(rend[0])
        #íŒ¨ë”©ì„ ì œê±°í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë˜ëŒë¦¼
        images_cutpad = [] 
        for s in range(len(images_delta)):
            images_cutpad.append(images_delta[s][:, args.patch_size:ori_shape[s][1]+args.patch_size, args.patch_size:ori_shape[s][2]+args.patch_size]) #íŒ¨ì¹˜ë¥¼ ì´ë¯¸ì§€ì— ì ìš©
        # out = net(images_delta[:, :, args.patch_size:300+args.patch_size, args.patch_size:300+args.patch_size])
        
        #ê°ì²´íƒì§€ì†ì‹¤ ê³„ì‚°
        loss = 0
        for s in range(len(images_cutpad)):
            trainer.reset_meters()
            loss_cls = trainer.forward(images_cutpad[s].unsqueeze(0), bboxes[s].unsqueeze(0), labels[s].unsqueeze(0), scales[s]) #cls ì†ì‹¤í•¨ìˆ˜ë“¤ì„ êµ¬í•´ì˜´
            loss += loss_cls.rpn_cls_loss + loss_cls.roi_cls_loss #faster-rcnnì˜ ì†ì‹¤í•¨ìˆ˜ë“¤ì¸ roi,rpn cls_lossë¥¼ ê°€ì ¸ì˜´
        loss /= len(images_cutpad) #ì†ì‹¤í•¨ìˆ˜ì˜ í‰ê· 
        
        #ìµœì¢…ì†ì‹¤ê³„ì‚° ë° ì—­ì „íŒŒ
        loss_adv = - loss #ì ëŒ€ì  ê³µê²©ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ ë¶€í˜¸ë¥¼ ë°˜ëŒ€ë¡œ ë°”ê¿”ì¤Œ (ì ëŒ€ì  ê³µê²©ì´ë‹ˆê¹ ì†ì‹¤í•¨ìˆ˜ê°€ í´ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ)
        loss_total = loss_adv + args.beta * loss_per #ì§€ê°ì†ì‹¤í•¨ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬ íŒ¨ì¹˜ê°€ ë„ˆë¬´ ì™œê³¡ë˜ì§€ ì•Šë„ë¡ í•¨ (ì´ì œ ìµœì¢… ì†ì‹¤í•¨ìˆ˜ê°€ ë§Œë“¤ì–´ì§)
       
        #ìµœì í™” (íŒ¨ì¹˜ ì—…ë°ì´íŠ¸)
        optimizer.zero_grad()
        loss_total.backward() #ì—­ì „íŒŒ ìˆ˜í–‰
        if not args.patch_place == "fix_patch":
            inan = group.grad.isnan()
            group.grad.data[inan] = 0
            
            # í™ˆ ì´ì™¸ ë¶€ë¶„ì€ grad=0
            #group.grad[:, ~groove_mask, :] = 0
            
            # Yì¶•ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì¶•ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
            group.grad[..., [0,2]] = 0  # Xì¶•(0)ê³¼ Zì¶•(2)ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ 0ìœ¼ë¡œ
            
        optimizer.step()
        '''
        groupì„ í…ì„œë¡œ ë³€í˜•ì‹œì¼œì„œ í›ˆë ¨í•  ìˆ˜ ìˆê²Œ ë§Œë“¬
        groupì€ ì ëŒ€ì  ê°ì²´ì— ëŒ€í•œ 3D ì¢Œí‘œ (vertex)ë¥¼ ê°€ì§€ê³  ìˆìŒ
        ex)
        group = [  [[0.1, 0.2, 0.3],  #ì ëŒ€ì  ê°ì²´ 1
                    [0.4, 0.5, 0.6], 
                    [0.7, 0.8, 0.9], 
                    [0.2, 0.3, 0.4], 
                    [0.5, 0.6, 0.7]], 

                    [[0.2, 0.3, 0.4], #ì ëŒ€ì  ê°ì²´ 2
                    [0.5, 0.6, 0.7], 
                    [0.8, 0.9, 1.0], 
                    [0.3, 0.4, 0.5], 
                    [0.6, 0.7, 0.8]]] 
        ëŒ€ì¶© ì´ëŸ°ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ì„œ ë§ˆì¹˜ W ë§ˆëƒ¥ ì—…ë°ì´íŠ¸ê°€ ê°€ëŠ¥í•œ ê²ƒ            
        ''' 
        torch.cuda.synchronize()
        
        print("Iter: {}/{}, L_adv = {:.3f}, Î²L_per = {:.3f}, Total loss = {:.3f}, Time: {:.2f}".format(
            t+1, args.num_iters, loss_adv.item() * 1000, args.beta * loss_per.item() * 1000,
            loss_total.item() * 1000, time.time() - timer))
            
    print("Calculate best place after attack...")
    '''
    ì´ì „ê³¼ì •ë“¤ì€ ì¼ë‹¨ ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ê³  í•´ë‹¹ ìœ„ì¹˜ì—ì„œ ê³µê²©ì„ ìœ„í•œ íŒ¨ì¹˜ë¥¼ ì œì‘
    ì´í›„ì—ëŠ” ì œì‘ëœ íŒ¨ì¹˜ë¥¼ ê°€ì§€ê³  ë” íš¨ê³¼ì ì¸ ìœ„ì¹˜ë¥¼ ì°¾ìŒ 
    í  ê·¼ë° ì´ ë¶€ë¶„ì€ reinforce ìœ„ì¹˜ì„ íƒì„ ìœ„í•´ ì¡´ì¬í•˜ì§€ ì•Šë‚˜ ì‹¶ìŒ
    '''
    group_clamp = torch.clamp(group, 0, 1) #group (ì ëŒ€ì  ê°ì²´)ë¥¼ 0~1ì‚¬ì´ë¡œ ë²”ìœ„ ì¬ì¡°ì •
    depth_clamp = torch.clamp(depth_patch, 0, 1)
    images_adv = [pad(e).clone().detach() for e in images] #íŒ¨ì¹˜ë¥¼ ì ìš©í•  ì›ë³¸ ì´ë¯¸ì§€
    for pt in range(args.patch_count):
        if not args.patch_place == "fix_patch":
            depth_img = renderer.ball2depth(group_clamp[pt], faces, args.patch_size, args.patch_size).unsqueeze(0).unsqueeze(0)
        else:
            depth_img = depth_clamp[:, pt:pt+1]
        # simulate function needs a 4-dimension input
        rend, mask = renderer.simulate(depth_img, args.patch_material)
        rend[~mask] = 1
        for s in range(len(images_adv)):
            u, v = areas_choose[s][pt]
            images_adv[s][:, u+args.patch_size:u+2*args.patch_size, v+args.patch_size:v+2*args.patch_size].mul_(rend[0])

    images_cutpad = []
    for s in range(len(images_adv)):
        images_cutpad.append(images_adv[s][:, args.patch_size:ori_shape[s][1]+args.patch_size, args.patch_size:ori_shape[s][2]+args.patch_size])
        
    return images_cutpad, areas_choose, torch.clamp(group, 0, 1), faces
    '''
    íŒ¨ì¹˜ê°€ ì ìš©ëœ ì´ë¯¸ì§€,
    ìµœì ì˜ ìœ„ì¹˜,
    íŒ¨ì¹˜ì˜ ëª¨ì–‘ return
    '''

def save_img(path, img_tensor, shape):
    img_tensor = img_tensor.cpu().detach().numpy().astype(np.uint8)
    img = img_tensor.transpose(1, 2, 0)
    img = cv2.resize(img, (shape[1], shape[0]))
    cv2.imwrite(path, img)

if __name__ == "__main__":
    if args.dataset == "OPIXray":
        data_info = config.OPIXray_test
    elif args.dataset == "HiXray":
        data_info = config.HiXray_test

    num_classes = len(data_info["model_classes"]) + 1
    net = FasterRCNNVGG16(config.FasterRCNN, num_classes - 1)
    
    '''
    ë³‘ë ¬í•™ìŠµ ë¶€ë¶„ ìˆ˜ì •
    '''
    state_dict = torch.load(args.ckpt_path)
    new_state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
    net.load_state_dict(new_state_dict)

    net.cuda()
    #net.load_state_dict(torch.load(args.ckpt_path))
    
    gpu_count = torch.cuda.device_count()
    print("CUDA is available:", torch.cuda.is_available())
    print("CUDA visible device count:", gpu_count)
    
    if gpu_count > 1:
        print(f"Using {gpu_count} GPUs via DataParallel!")
        net = nn.DataParallel(net, device_ids=[0, 1])  # GPU 0, 1 ì‚¬ìš©
        
    trainer = FasterRCNNTrainer(net, config.FasterRCNN, num_classes).cuda()
    net.eval()

    dataset = RCNNDetectionDataset(root=data_info["dataset_root"], 
                               model_classes=data_info["model_classes"],
                               image_sets=data_info["imagesetfile"], 
                               target_transform=RCNNAnnotationTransform(data_info["model_classes"]), 
                               phase='test')
    data_loader = DataLoader(dataset, args.batch_size, shuffle=True, collate_fn=rcnn_detection_collate_attack, pin_memory=True)

    num_images = len(dataset)

    if not os.path.exists(args.save_path):
        os.makedirs(args.save_path)
        
    img_path = os.path.join(args.save_path, "adver_image")
    if not os.path.exists(img_path):
        os.makedirs(img_path)
        
    obj_path = os.path.join(args.save_path, "adver_obj")
    if not os.path.exists(obj_path):
        os.makedirs(obj_path)

    for i, (images, bboxes, labels, scales, img_ids) in enumerate(data_loader):
        print("Batch {}/{}...".format(i+1, math.ceil(num_images / args.batch_size)))
        print(img_ids)
        if args.patch_place != "none":
            images_adv, areas_choose, vertices, faces =  attack(images, bboxes, labels, net, trainer)
        else:
            images_adv = images
            faces = None
        
        print("Saving...")
        for t in range(len(images_adv)):
            shape = images_adv[t].shape[1:]
            shape = [int(shape[0] / scales[t]), int(shape[1] / scales[t])]
            save_img(os.path.join(img_path, img_ids[t] + ".png"), images_adv[t] * 255, shape)
            if faces is not None:
                for i in range(vertices.shape[0]):
                    renderer.save_to_file(
                        os.path.join(obj_path, str(img_ids[t]) + "_u{}_v{}.obj".format(*areas_choose[t][i])), 
                        vertices[i], faces)